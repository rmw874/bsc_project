import argparse
import logging
from pathlib import Path

import pandas as pd
from albumentations import Compose
from albumentations.pytorch import ToTensorV2
from torch.utils.data import DataLoader
from tqdm import tqdm

from dataset import MGRDataset
from inference import postprocess_images

logger = logging.getLogger(__name__)

# This is hardcoded and only applies to birth book pages
# TODO: Implement solution for the other book types (deaths, weddings, confirmations)
COLUMN_NAMES = ["BIRTHDATE", "CHILD_NAME", "PARENTS"]
COLUMN_PAIRS = [(0, 1), (2, 3), (3, 4)]


def run(args):
    # Setup logging
    logging.basicConfig(
        format="%(asctime)s - %(levelname)s - %(name)s -   %(message)s",
        datefmt="%d/%m/%Y %H:%M:%S",
        level=logging.INFO,
    )
    # Define and create (sub-)folders

    # Base output dir
    output_dir = Path(args.output_dir)
    output_dir.mkdir(exist_ok=True)

    # Folders for main segmentation outputs (cells)
    cells_output_dir = output_dir / "cells"
    cells_output_dir.mkdir(exist_ok=True)

    for column_name in COLUMN_NAMES:
        (cells_output_dir / column_name.lower() / "image").mkdir(exist_ok=True, parents=True)
    (cells_output_dir / "id" / "image").mkdir(exist_ok=True, parents=True)

    # Folder for U-Net predictions
    if args.save_predict:
        unet_predictions_dir = output_dir / "unet_predictions"
        unet_predictions_dir.mkdir(exist_ok=True)
    else:
        unet_predictions_dir = None

    # Folder for illustrations, i.e. bounding boxes drawn on resized versions of the input images
    if args.save_illustrations:
        illustrations_output_dir = output_dir / "illustrations"
        illustrations_output_dir.mkdir(exist_ok=True)
    else:
        illustrations_output_dir = None

    # Folders for illustrations of failed images
    if args.save_failed:
        failed_output_dir = output_dir / "failed"
        failed_output_dir.mkdir(exist_ok=True)
        for column_name in COLUMN_NAMES:
            (failed_output_dir / column_name.lower()).mkdir(exist_ok=True)
    else:
        failed_output_dir = None

    # Define default config for segmenter
    config = {
        "illustration_dir": illustrations_output_dir,
        "cells_dir": cells_output_dir,
        "unet_pred_dir": unet_predictions_dir,
        "failed_dir": failed_output_dir,
    }

    # Log settings
    logger.info(f"Segmentation arguments {args.__dict__}")
    logger.info(f"Config {config}")

    # Start timer    t_start = timer()

    logger.info("Finding images")

    file_paths = Path(args.img_csv)
    if not file_paths.is_dir() and file_paths.suffix == ".csv":
        file_paths = list(pd.read_csv(file_paths)["folders"].values)
    else:
        file_paths = [file_paths]

    transform = Compose([
        ToTensorV2(transpose_mask=True),
    ])

    # Create dataset and data loader
    dataset = MGRDataset(folders=file_paths, transform=transform, return_name=True)

    dataloader = DataLoader(
        dataset,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        drop_last=False, shuffle=False
    )

    pred_acc = []
    img_acc = []
    name_acc = []
    for images, labels, names in tqdm(dataloader, "Inference (in number of batches)", total=len(dataloader)):
        img_acc.append(images)
        name_acc.append(names)
        pred_acc.append(labels)

        if len(pred_acc)% args.acc_steps == 0:
            logging.info("Start post processing of images")
            postprocess_images(img_acc, name_acc, pred_acc, config, args.num_post_workers)

            pred_acc = []
            img_acc = []
            name_acc = []

    if len(pred_acc) > 0:
        postprocess_images(img_acc, name_acc, pred_acc, config, args.num_post_workers)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Inference script for UNet model for column/row line detection")
    parser.add_argument("--img_csv", type=str, required=True,
                        help="Path to the csv file containing paths to images to predict or folders with images "
                             "(use the split.csv generated by create_datasplit.py)."
                             "If parameter is a folder or does not end with 'csv', "
                             "we assume that an image/folder is given directly")
    parser.add_argument("--acc_steps", type=int, default=64, help="Number of postprocessed batches at the same time")
    parser.add_argument("--batch_size", type=int, default=16, help="Batch size for training and validation")
    parser.add_argument("--num_workers", type=int, default=4, help="Number of workers per dataloader")
    parser.add_argument("--num_post_workers", type=int, default=16, help="Number of workers for postprocessing")
    parser.add_argument("--output_dir", type=str, default="out_sanity", help="Path to output directory")
    parser.add_argument("--save_predict", action='store_true', default=False,
                        help="Flag to enable saving of predictions")
    parser.add_argument("--save_failed", action='store_true', default=False,
                        help="Flag to enable saving of failed images")
    parser.add_argument("--save_illustrations", action='store_true', default=False,
                        help="Flag to enable saving of illustration images")

    args = parser.parse_args()

    run(args)
