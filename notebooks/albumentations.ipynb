{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import OneOf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (3200 // 2, 2496 // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rectangle(img):\n",
    "    width, height = img.shape[1], img.shape[0]\n",
    "    start_point_right = (math.ceil(0.5*width), 0)\n",
    "    end_point_right = (width, height)\n",
    "    color = (255,255,255)\n",
    "    img = cv2.rectangle(img, start_point_right, end_point_right, color, -1)\n",
    "        \n",
    "    start_point_left = (0, 0)\n",
    "    end_point_left = (math.floor(width*0.08), height)\n",
    "    img = cv2.rectangle(img, start_point_left, end_point_left, color, -1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vertical_line_bounds(img):\n",
    "    \"\"\"Find the leftmost and rightmost vertical lines in left half of image\"\"\"\n",
    "    vertical = np.copy(img)\n",
    "    \n",
    "    # nothing relevant on right-half of image.\n",
    "    half = img.shape[1] // 2\n",
    "    vertical = vertical[:, :half]\n",
    "    \n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 50))\n",
    "    vertical = cv2.morphologyEx(vertical, cv2.MORPH_CLOSE, vertical_kernel)\n",
    "    \n",
    "    col_profile = np.sum(vertical == 0, axis=0)  # Sum black pixels\n",
    "    \n",
    "    threshold = np.max(col_profile) * 0.15 \n",
    "    line_cols = np.where(col_profile > threshold)[0]\n",
    "    \n",
    "    if len(line_cols) > 1:  # Make sure we have at least 2 lines\n",
    "        left_bound = max(0, line_cols[0] - 10)\n",
    "\n",
    "        right_bound = min(half, line_cols[-1] -5)\n",
    "        return left_bound, right_bound\n",
    "    \n",
    "    return 0, img.shape[1]\n",
    "\n",
    "def preprocess(img, BS=13, C=12):\n",
    "    \"\"\"Modified preprocessing pipeline with vertical line removal\"\"\"\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    img = cv2.adaptiveThreshold(\n",
    "        img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, blockSize=BS, C=C\n",
    "    )\n",
    "    img = add_rectangle(img)\n",
    "    \n",
    "    # Clean noise\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    \n",
    "    left_bound, right_bound = find_vertical_line_bounds(img)\n",
    "    \n",
    "    # Apply bounds\n",
    "    img[:, :left_bound] = 255\n",
    "    img[:, right_bound:] = 255\n",
    "    \n",
    "    # Normalize and resize\n",
    "    img = img.astype(float) / 255.0\n",
    "    img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "albumentations_transform = A.Compose([\n",
    "    # Rotation - keeping this modest since text is vertical\n",
    "    A.Affine(\n",
    "        rotate=(-5, 0),\n",
    "        p=0.6,\n",
    "        mode=cv2.BORDER_CONSTANT,\n",
    "        cval=1,  # Using 1 for white since image is normalized\n",
    "        interpolation=cv2.INTER_NEAREST,\n",
    "    ),\n",
    "    \n",
    "    # Shear - reduced for structural preservation\n",
    "    A.Affine(\n",
    "        shear=(-3, 3),\n",
    "        p=0.6,\n",
    "        mode=cv2.BORDER_CONSTANT,\n",
    "        cval=1,\n",
    "        interpolation=cv2.INTER_NEAREST,\n",
    "    ),\n",
    "    \n",
    "    # Translation\n",
    "    A.Affine(\n",
    "        translate_percent={\"x\": (-0.05, 0.05)},  # Reduced y-range\n",
    "        p=0.6,\n",
    "        mode=cv2.BORDER_CONSTANT,\n",
    "        cval=1,\n",
    "        interpolation=cv2.INTER_NEAREST,\n",
    "    ),\n",
    "    \n",
    "    # Elastic Transform\n",
    "    A.ElasticTransform(\n",
    "        alpha=50.0,\n",
    "        sigma=20,\n",
    "        p=0.3,\n",
    "        border_mode=cv2.BORDER_CONSTANT,\n",
    "        value=1,\n",
    "    ),\n",
    "    \n",
    "    # Grid Distortion - for subtle warping\n",
    "    A.GridDistortion(\n",
    "        num_steps=5,\n",
    "        distort_limit=0.2,\n",
    "        p=0.3,\n",
    "        border_mode=cv2.BORDER_CONSTANT,\n",
    "        value=1,\n",
    "    ),\n",
    "    \n",
    "    # Optical Distortion - for lens-like effects\n",
    "    A.OpticalDistortion(\n",
    "        distort_limit=0.2,\n",
    "        shift_limit=0.2,\n",
    "        p=0.3,\n",
    "        border_mode=cv2.BORDER_CONSTANT,\n",
    "        value=1,\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "albumentations_transform = A.Compose([\n",
    "    # Controlled rotation\n",
    "    A.Affine(\n",
    "        rotate=(-1, 1),  \n",
    "        p=0.3,\n",
    "        mode=cv2.BORDER_CONSTANT,\n",
    "        cval=255,\n",
    "    ),\n",
    "    \n",
    "    # Minimal shear\n",
    "    A.Affine(\n",
    "        shear=(-1, 1),  \n",
    "        p=0.3,\n",
    "        mode=cv2.BORDER_CONSTANT,\n",
    "        cval=255,\n",
    "    ),\n",
    "    \n",
    "    # Column-aware translation\n",
    "    A.Affine(\n",
    "        translate_percent={\"x\": (-0.02, 0.02)},\n",
    "        p=0.5,\n",
    "        mode=cv2.BORDER_CONSTANT,\n",
    "        cval=255,\n",
    "    ),\n",
    "    \n",
    "    # Very subtle elastic transform\n",
    "    A.ElasticTransform(\n",
    "        alpha=20.0,\n",
    "        sigma=8,\n",
    "        p=0.2,\n",
    "        border_mode=cv2.BORDER_CONSTANT,\n",
    "        value=1,\n",
    "    ),\n",
    "], additional_targets={'mask': 'mask'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_transformations(image, transform, num_examples=5):\n",
    "    fig, axes = plt.subplots(1, num_examples, figsize=(15, 5))\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        augmented = transform(image=image)['image']\n",
    "    \n",
    "        if num_examples == 1:\n",
    "            ax = axes\n",
    "        else:\n",
    "            ax = axes[i]\n",
    "            \n",
    "        ax.imshow(augmented, cmap='gray', vmin=0, vmax=1)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_elastic_transforms(image):\n",
    "    # Create different elastic transforms\n",
    "    transforms = [\n",
    "        (\"Original\", None),\n",
    "        (\"Low α=10, Low σ=10\", A.ElasticTransform(alpha=10.0, sigma=10, p=1)),\n",
    "        (\"High α=100, Low σ=10\", A.ElasticTransform(alpha=100.0, sigma=10, p=1)),\n",
    "        (\"Low α=10, High σ=200\", A.ElasticTransform(alpha=10.0, sigma=200, p=1)),\n",
    "        (\"High α=100, High σ=200\", A.ElasticTransform(alpha=100.0, sigma=200, p=1))\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(transforms), figsize=(20, 4))\n",
    "    \n",
    "    for idx, (title, transform) in enumerate(transforms):\n",
    "        if transform is None:\n",
    "            aug_image = image\n",
    "        else:\n",
    "            aug_image = transform(image=image)['image']\n",
    "            \n",
    "        axes[idx].imshow(aug_image, cmap='gray', vmin=0, vmax=1)\n",
    "        axes[idx].set_title(title)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "albumentations_transform = A.Compose([\n",
    "    # Slight rotations for page tilt\n",
    "    A.Affine(rotate=(-2, 2), p=0.9),\n",
    "    \n",
    "    # Blur for focus variations\n",
    "    A.GaussianBlur(blur_limit=(3, 5), p=0.4),\n",
    "    \n",
    "    # Slight vertical stretching/compression\n",
    "    A.Affine(scale={\"y\": (0.95, 1.05)}, p=0.5),\n",
    "    \n",
    "    # Very minimal horizontal shear\n",
    "    A.Affine(shear=(-1, 1), p=0.4)\n",
    "], additional_targets={'mask': 'mask'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the image\n",
    "image_path = r\"..\\data\\processed\\images\\8013620831-0054.jpg-b.jpg\"\n",
    "\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "if image is None:\n",
    "    raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
    "\n",
    "img = preprocess(image)\n",
    "\n",
    "visualize_transformations(img, albumentations_transform)\n",
    "# compare_elastic_transforms(img)\n",
    "# compare_brightness_contrast(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv_3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
